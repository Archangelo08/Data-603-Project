---
title: "Data 603 Project"
author: "Ahuchogu, Divine | Ouano, Archangelo - 30235358"
date: "2023-11-28"
output: pdf_document
header-includes: \usepackage{fvextra} \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(binom)
library(car)
library(collapsibleTree)
library(dbplyr)
library(dplyr)
library(EnvStats)
library(ggformula)
library(ggplot2)
library(gmodels)
library(htmltools)
library(ISLR)
library(knitr)
library(lawstat)
library(markdown)
library(mosaic)
library(mdsr)
library(mosaicData)
library(nycflights13)
library(olsrr)
library(plyr)
library(purrr)
library(plotly)
library(resampledata)
library(rmarkdown)
library(rpart)
library(rpart.plot)
library(rvest)
library(SDaA)
library(shiny)
library(stringi)
library(tibble)
library(tidyr)
library(tidyselect)
library(tinytex)
library(yaml)
library(shiny)
library(leaps)
library(GGally)
```

# Chapter 1: Introduction

1.1 Motivation

1.1.1 Context
* Clearly state the context and applied domain of your project

1.1.2 Problem
* What problem are we going to address?

1.2 Objectives

1.2.1 Overview
* What is the overall intent of the project?

1.2.2 Goals & Research Questions
* Clearly state each of your data/visual analytics goals and research questions for data modelling. What are your expectations? Why is this project important to you?


# Chapter 2: Methodology

2.1 Data
* Briefly describe the data set, source, how it was collected, number of attributes and a brief description of each attribute

2.2 Approach
* What approach are we going to try to address your problems? Why do we think it will work well?

2.3 Workflow
* What steps (workflow task list) are required? Which of these steps is particularly hard? What to do if the hard steps don't work out?

2.4 Workload Distribution
* Briefly describe the group member's workload distribution and responsibilities







# Chapter 3: Main Results of the Analysis

3.1 Results
* What do my results indicate? Do you have any unexpected results?

## Fitting the Full model

```{r}
concretedata = read.csv("https://raw.githubusercontent.com/Archangelo08/Data-603-Project/main/cleanedconc_data.csv", header=TRUE)
head(concretedata, 6)
tail(concretedata, 5)
```

Creating the Full model:

```{r}
fullmodel = lm(Concrete_compressive_strength~Cement+Blast_Furnace_Slag+Fly_Ash+Water+Superplasticizer+Coarse_Aggregate+Fine_Aggregate+Age, data=concretedata)
summary(fullmodel)
```

**Choosing the Best model using the following regression procedures:**  
* Stepwise Regression Procedure  
* Backward Elimination Procedure  
* Forward Selection Procedure  
* All-Possible-Regression Selection Procedure


Using **Stepwise Regression Procedure**:

```{r}
stepfullmodel=ols_step_both_p(fullmodel, pent=0.05, prem=0.1, details=FALSE)
summary(stepfullmodel$model)
```

Using **Backward Elimination Procedure**:

```{r}
backfullmodel = ols_step_backward_p(fullmodel, prem=0.1, details=FALSE)
summary(backfullmodel$model)
```

By using the Backward Elimination Procedure, it provides the following first-order regression model:  
$\beta_{0}+\beta_{1}Cement+\beta_{2}Blast\_Furnace\_Slag+\beta_{3}Water+\beta_{4}Fine\_Aggregate+\beta_{5}Age$. However, the p-value of Fine_Aggregate is > 0.05, so this will be dropped from the model. 

Using **Forward Selection Procedure**

```{r}
forwardfullmodel = ols_step_forward_p(fullmodel, penter=0.05, details=FALSE)
summary(forwardfullmodel$model)
```

Using **All-Possible-Regression selection procedure**:

```{r}
best_subset = regsubsets(Concrete_compressive_strength~Cement+Blast_Furnace_Slag+Fly_Ash+Water+Superplasticizer+Coarse_Aggregate+Fine_Aggregate+Age, data=concretedata, nv=8)
summary(best_subset)
```

```{r}
reg_summary = summary(best_subset)
rsquare = c(reg_summary$rsq)
cp = c(reg_summary$cp)
AdjustedR = c(reg_summary$adjr2)
RMSE = c(reg_summary$rss)
BIC = c(reg_summary$bic)
cbind(rsquare,cp,BIC,RMSE,AdjustedR)
```

```{r}
par(mfrow=c(3,2))
plot(reg_summary$cp,type="o",pch=10,xlab="Number of Variables",ylab="Cp")
plot(reg_summary$bic,type="o",pch=10,xlab="Number of Variables",ylab="BIC")
plot(reg_summary$rsq,type="o",pch=10,xlab="Number of Variables",ylab="R^2")
plot(reg_summary$rss,type="o",pch=10,xlab="Number of Variables",ylab="RMSE")
plot(reg_summary$adjr2,type="o",pch=10,xlab="Number of Variables",ylab="Adjusted R^2")
```

Based on the output above, we will be selecting 4 subset of predictor variables namely:  
* Cement  
* Blast_Furnace_Slag  
* Water  
* Age  

**Summary of best predictor variables selected by the different Regression selection procedures above:**

Stepwise:  
* Age  
* Cement  
* Blast_Furnace_Slag  
* Water

Backward Elimination:  
* Cement  
* Blast_Furnace_Slag  
* Water  
* Age  

Forward Selection:  
* Age  
* Cement  
* Blast_Furnace_Slage  
* Water  

All-Possible-Regression:  
* Cement  
* Blast_Furnace_Slag  
* Water  
* Age  

With these results, our **best first-order regression model** is the following:

```{r}
bestfirstorder = lm(Concrete_compressive_strength~Cement+Blast_Furnace_Slag+Water+Age, data=concretedata)
summary(bestfirstorder)
```

## Checking for Interactions and High-order Model

### Intearction terms

```{r}
bestFOinterac = lm(Concrete_compressive_strength~(Cement+Blast_Furnace_Slag+Water+Age)^2, data=concretedata)
summary(bestFOinterac)
```

Using partial T test to drop interaction terms that are not significant in predicting the response variable, with $\alpha = 0.05$, the only interaction terms that are significant are the following:  
* Cement:Blast_Furnace_Slag  
* Cement:Age  

```{r}
bestFOredinterac = lm(Concrete_compressive_strength~Cement+Blast_Furnace_Slag+Water+Age+Cement:Blast_Furnace_Slag+Cement:Age, data=concretedata)
summary(bestFOredinterac)
```

Comparing the best first-order model with the same regression model, but with interaction terms (significant only):  
Best First-order regression model:  
* RMSE = 8.39  
* Adjusted R-squared = 0.6519  

Best First-order regression model, including significant interaction terms:  
* RMSE = 8.071  
* Adjusted R-squared = 0.6778

**We can infer that the best first-order model that includes significant interaction terms is better.**

### High-order model

```{r}
bestFOconcretedata = data.frame(
  concretedata$Concrete_compressive_strength,
  concretedata$Cement,
  concretedata$Blast_Furnace_Slag,
  concretedata$Water,
  concretedata$Age)

ggpairs(bestFOconcretedata,
        lower=list(continuous="smooth_loess",combo="facethist",discrete="facetbar",na="na"), progress=FALSE)
```

Based on the ggpairs matrix visual, the predictor variable that potentially supports high-order model are:  
* Blast_Furnace_Slag
* Age (maybe)

Let's create the regression model that includes high-order model:

```{r}
secondordermodel = lm(Concrete_compressive_strength~Cement + poly(Blast_Furnace_Slag,2,raw=T) + Water + poly(Age,2,raw=T) + Cement:Blast_Furnace_Slag + Cement:Age, data=concretedata)
summary(secondordermodel)
```

Based on the output above, transforming Blast_Furnace_Slag predictor variable into a high-order model turned out to be not significant in predicting the response variable. On the other hand, Age is. Let's check if transforming Age into its third order is still significant:

```{r}
thirdordermodel = lm(Concrete_compressive_strength~Cement + Blast_Furnace_Slag + Water + poly(Age,3,raw=T) + Cement:Blast_Furnace_Slag + Cement:Age, data=concretedata)
summary(thirdordermodel)
```

It turns out transforming Age into its third model is not significant with p value > 0.05. So, we'll stop at its second order model.

**This is the best regression model, including interaction terms and high-order model:**

```{r}
bestmodel = lm(Concrete_compressive_strength~Cement + Blast_Furnace_Slag + Water + poly(Age,2,raw=T) + Cement:Blast_Furnace_Slag + Cement:Age, data=concretedata)
summary(bestmodel)
```

After we have applied a high-order transformation on the Age predictor variable the interaction term Cement:Age turned out to be insignificant in predicting the response variable, so we will be dropping this.

```{r}
bestmodel = lm(Concrete_compressive_strength~Cement + Blast_Furnace_Slag + Water + poly(Age,2,raw=T) + Cement:Blast_Furnace_Slag, data=concretedata)
summary(bestmodel)
```



Comparing the regression model that includes only interaction terms and the regression model that includes both interaction terms and high-order model:  
Best regression model only interaction terms:  
* RMSE = 8.071  
* Adjusted R-squared = 0.6778

Best regression model with interaction terms and high-order model:  
* RMSE = 7.376  
* Adjusted R-squared = 0.731

We can infer that the regression model that includes both interaction terms and high-order model (all significant) is better.

**This is the best model after using the different regression selection procedures and including both interaction terms and high-order model**

$\widehat{Concrete\_compressive\_strength}$ = 25.3809 + (0.0775459+0.0003171Blast_Furnace_Slag)Cement + (0.0065590+0.0003171)Blast_Furnace_Slag + 0.8578Age - 0.0050Age^2


## Checking the Regression Assumptions

**Linearity Assumption**

*You need to check this later*
```{r}
# Extract residuals from the best model
residuals_bestmodel <- residuals(bestmodel)

# 1. Linearity Assumption: Residual plots
#par(mfrow=c(2,2))
#plot(bestmodel)

plot(bestmodel, col = "red", which = 1) #for residual vs fitted plot
plot(bestmodel, col = "blue", which = 2) #for Q-Q Residuals plot
plot(bestmodel, col = "green", which = 3) #for Scale-Location plot

```

**Equal Variance Assumption**

Defining the Hypothesis test:

$$
\begin{aligned}
H_{0} &: \text{Heteroscedasticity does not exist} \\
H_{A} &: \text{Heteroscedasticity does exist}
\end{aligned}
$$

Using the Breusch-Pagan test to check for Heteroscedasticity:

```{r}
bptest(bestmodel)
```

```{r}
library(mctest)
library(lmtest)
library(MASS)

cat("H0: The population sample follows a normal distribution.
    \n HA: The population sample does not follow a normal distribution. \n")

# 2. Normality Assumption: Shapiro-Wilk normality test
shapiro.test(residuals(bestmodel))

cat(" Given that p-value = 0.8049 which tells us that the residuals are perfectly normally distributed, we fail to reject the null hypothesis at 0.05 significant level.")


ggplot(data = concretedata, aes(sample=bestmodel$residuals)) + stat_qq() + stat_qq_line()

```




```{r}

```

```{r}
# 3. FOR MULTICOLLINEARITY: Variance Inflation Factors (VIF)

#Since our best model is a higher order model, we will perform the VIF on the first order model instead of the higher order model.

firstordermodel = lm(Concrete_compressive_strength~Cement+Blast_Furnace_Slag+Water+Age, data=concretedata)

vif(firstordermodel)

imcdiag(firstordermodel, method="VIF")


#Performing it on our best model gives us multicollinearity as seen below
 
imcdiag(bestmodel, method="VIF")

```

```{r}

# 4. Outliers: Cookâ€™s distance and leverage

# Rewrite the said model
bestmodel <- lm(Concrete_compressive_strength ~ Cement + Blast_Furnace_Slag + Water + poly(Age, 2, raw = TRUE) + Cement:Blast_Furnace_Slag, data = concretedata)

residuals <- residuals(bestmodel)

# Create a boxplot for residuals
boxplot(residuals, main = "Residuals Boxplot", ylab = "Residuals")
plot(bestmodel, col = "red", which = 4)

```


```{r}
#Prediction


# Make sure the variable names match those in your original model
new_data <- data.frame(
  Cement = c(213.8),
  Blast_Furnace_Slag = c(98.1),
  Water = c(181.7),
  Age = c(14)
  
)

confidence_level <- 0.95

# Use the model to make predictions
predictions <- predict(bestmodel, newdata = new_data, interval = "predict", level = confidence_level)


print(predictions)



```


```{r}





```


# Chapter 4: Conclusion and Discussion

4.1 Approach
* Overall, is the approach we took promising? Please elaborate. What different approach or variant of this approach is better?

4.2 Future Work
What should follow-up work be done next?



